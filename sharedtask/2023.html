<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.16.4 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>2023 BEA Shared Task - SIGEDU</title>
<meta name="description" content="ACL Special Interest Group for Building Educational Applications.">



<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="SIGEDU">
<meta property="og:title" content="2023 BEA Shared Task">
<meta property="og:url" content="http://localhost:4000/sharedtask/2023">






  <meta name="twitter:site" content="@aclsigedu">
  <meta name="twitter:title" content="2023 BEA Shared Task">
  <meta name="twitter:description" content="ACL Special Interest Group for Building Educational Applications.">
  <meta name="twitter:url" content="http://localhost:4000/sharedtask/2023">

  
    <meta name="twitter:card" content="summary">
    
  

  







  

  


<link rel="canonical" href="http://localhost:4000/sharedtask/2023">







  <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Person",
      "name": "SIGEDU",
      "url": "http://localhost:4000",
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="SIGEDU Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if IE ]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->
<link rel="apple-touch-icon" sizes="57x57" href="/assets/images/apple-touch-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="/assets/images/apple-touch-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="/assets/images/apple-touch-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="/assets/images/apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="/assets/images/apple-touch-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="/assets/images/apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="/assets/images/apple-touch-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="/assets/images/apple-touch-icon-152x152.png">
<link rel="icon" type="image/png" href="/assets/images/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/assets/images/favicon-16x16.png" sizes="16x16">
<link rel="manifest" href="/assets/images/manifest.json">
<link rel="mask-icon" href="/assets/images/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#2b5797">
<meta name="msapplication-TileImage" content="/assets/images/mstile-144x144.png">
<meta name="theme-color" content="#ffffff">

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/"><img src="/assets/images/logos/sigedu-long-logo.png" alt=""></a>
        
        <a class="site-title" href="/"> </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/constitution" >Constitution</a>
            </li><li class="masthead__menu-item">
              <a href="/officers" >Officers</a>
            </li><li class="masthead__menu-item">
              <a href="/members" >Members</a>
            </li><li class="masthead__menu-item">
              <a href="/news" >News</a>
            </li><li class="masthead__menu-item">
              <a href="/blog" >Blog</a>
            </li><li class="masthead__menu-item">
              <a href="/bea/current" >BEA Workshop</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  
  
    
      
        <img src=
        
          "/assets/images/sharedtask/2023.png"
        
        alt="shared task illustration">
      
      <h3>Generating AI Teacher Responses in Educational Dialogues</h3>
      <p>Shared task organized during the <a href="/bea/2023">BEA</a> workshop at <a href="https://2023.aclweb.org">ACL 2023</a>.<br /> Toronto, Canada <br /> July 13, 2023</p>

      

<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">Toggle menu</label>
  <ul class="nav__items">
    
      <li>
        
          <span class="nav__sub-title">CodaLab</span>
        

        
        <ul>
          
            
            

            
            

            <li><a href="https://codalab.lisn.upsaclay.fr/competitions/11705" class="">Competition</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Contact</span>
        

        
        <ul>
          
            
            

            
            

            <li><a href="mailto:bea.nlp.workshop@gmail.com" class="">bea.nlp.workshop@gmail.com</a></li>
          
        </ul>
        
      </li>
    
  </ul>
</nav>
    
    
  
  </div>


  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="2023 BEA Shared Task">
    
    
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">2023 BEA Shared Task
</h1>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right ">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu">
  <li><a href="#">Generating AI Teacher Responses in Educational Dialogues</a>
    <ul>
      <li><a href="#motivation-goal-and-purpose">Motivation, Goal, and Purpose</a></li>
      <li><a href="#data">Data</a></li>
      <li><a href="#participation">Participation</a>
        <ul>
          <li><a href="#submission">Submission</a></li>
          <li><a href="#evaluation">Evaluation</a></li>
          <li><a href="#important-dates">Important Dates</a></li>
        </ul>
      </li>
      <li><a href="#references">References</a></li>
    </ul>
  </li>
</ul>
            </nav>
          </aside>
        
        <h1>Generating AI Teacher Responses in Educational Dialogues</h1>

<h2 id="motivation-goal-and-purpose">Motivation, Goal, and Purpose</h2>

<p>Conversational agents offer promising opportunities for education. They can fulfill various roles (intelligent tutors and service-oriented assistants) and pursue different objectives (e.g., improving student skills and increasing instructional efficiency) <a class="citation" href="#wollny_are_2021">(Wollny et al. 2021)</a>. Among all of these different vocations of an educational chatbot, the most prevalent one is the <strong>AI teacher</strong> helping a student with skill improvement and providing more opportunities to practice. Some recent meta-analyses have even reported a significant effect of chatbots on skill improvement, for example in language learning <a class="citation" href="#bibauw_dialogue_2022">(Bibauw et al. 2022)</a>. What is more, current advances in AI and natural language processing have led to the development of conversational agents that are founded on more powerful generative language models.</p>

<p>Despite these promising opportunities, the use of powerful generative models as a foundation for downstream tasks also presents several crucial challenges. In the educational domain in particular, it is important to ascertain whether that foundation is solid or flimsy. Bommasani et al. <a class="citation" href="#bommasani_opportunities_2021">(2021: pp. 67-72)</a> stressed that, if we want to put these models into practice as AI teachers, it is imperative to determine whether they can (a) speak to students like a teacher, (b) understand students, and (c) help students improve their understanding. Therefore, Tack and Piech <a class="citation" href="#tack_ai_2022">(2022)</a> formulated the <strong>AI teacher test challenge</strong>: How can we test whether state-of-the-art generative models are good AI teachers, capable of replying to a student in an educational dialogue?</p>

<p>Following the AI teacher test challenge, we organize a first <strong>shared task on the generation of teacher language in educational dialogues</strong>.
The goal of the task is to use NLP and AI methods to generate teacher responses in real-world samples of teacher-student interactions. These samples are taken from the <em>Teacher Student Chatroom Corpus</em> <a class="citation" href="#caines_teacherstudent_2020">(Caines et al. 2020; Caines et al. 2022)</a>. Each training sample is composed of a dialogue context (i.e., several teacher-student utterances) as well as the teacher’s response. For each test sample, participants are asked to submit their best generated teacher response.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[ DIALOGUE CONTEXT ]
Teacher: Yes, good! And to charge it up, you need to __ it ___
Student: …
Teacher: connect to the source of electricity 
Student: i understand
Teacher: plug it __?
Student: in

[ REFERENCE RESPONSE ]
Teacher: yes, good. And when the battery is full, you need to ____ (disconnect it)
</code></pre></div></div>

<p>The purpose of the task is to <strong>benchmark the ability of generative models to act as AI teachers, replying to a student in a teacher-student dialogue</strong>. Submissions are ranked according to several automated dialogue evaluation metrics <a class="citation" href="#yeh_comprehensive_2021">(Yeh et al. 2021)</a>, with the top submissions selected for further human evaluation. During this manual evaluation, human raters compare a pair of teacher responses in terms of three abilities: speak like a teacher, understand a student, help a student <a class="citation" href="#tack_ai_2022">(Tack &amp; Piech 2022)</a>. As such, we adopt an evaluation method that is akin to ACUTE-Eval for evaluating dialogue systems <a class="citation" href="#li_acuteeval_2019">(Li et al. 2019)</a>.</p>

<h2 id="data">Data</h2>

<p>The shared task is based on data from the <em>Teacher-Student Chatroom Corpus</em> (TSCC) <a class="citation" href="#caines_teacherstudent_2020">(Caines et al. 2020; Caines et al. 2022)</a>. This corpus comprises data from several chatrooms (102 in total) in which an ESL teacher interacts with a student in order to work on a language exercise and assess the student’s English language proficiency.</p>

<p>From each dialogue, several shorter passages were extracted. Each passage counts at most 100 tokens, is composed of several sequential teacher-student turns (i.e., the preceding dialogue context), and ends with a teacher utterance (i.e., the reference response). These short passages are the data samples used in this shared task.</p>

<p>The format is inspired by the JSON format used in ConvoKit <a class="citation" href="#chang_convokit_2020">(Chang et al. 2020)</a>.
Each <strong>training sample</strong> is given as a JSON object composed of three fields:</p>

<dl>
  <dt>id</dt>
  <dd>a unique identifier for this sample.</dd>
  <dt>utterances</dt>
  <dd>a list of utterances, which corresponds to the preceding dialogue context. Each utterance is a JSON object with a <code class="language-plaintext highlighter-rouge">"text"</code> field containing the utterance and a <code class="language-plaintext highlighter-rouge">"speaker"</code> field containing a unique label for the speaker.</dd>
  <dt>response</dt>
  <dd>a reference response, which corresponds to the final teacher’s utterance. Again, this utterance is a JSON object with a <code class="language-plaintext highlighter-rouge">"text"</code> field containing the utterance and a <code class="language-plaintext highlighter-rouge">"speaker"</code> field containing a unique label for the speaker.</dd>
</dl>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
    </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"train_0000"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"utterances"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"text"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Yes, good! And to charge it up, you need to __ it ___"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"speaker"</span><span class="p">:</span><span class="w"> </span><span class="s2">"teacher"</span><span class="p">,</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"text"</span><span class="p">:</span><span class="w"> </span><span class="s2">"…"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"speaker"</span><span class="p">:</span><span class="w"> </span><span class="s2">"student"</span><span class="p">,</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"text"</span><span class="p">:</span><span class="w"> </span><span class="s2">"connect to the source of electricity"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"speaker"</span><span class="p">:</span><span class="w"> </span><span class="s2">"teacher"</span><span class="p">,</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"text"</span><span class="p">:</span><span class="w"> </span><span class="s2">"i understand"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"speaker"</span><span class="p">:</span><span class="w"> </span><span class="s2">"student"</span><span class="p">,</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"text"</span><span class="p">:</span><span class="w"> </span><span class="s2">"plug it __?"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"speaker"</span><span class="p">:</span><span class="w"> </span><span class="s2">"teacher"</span><span class="p">,</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"text"</span><span class="p">:</span><span class="w"> </span><span class="s2">"in"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"speaker"</span><span class="p">:</span><span class="w"> </span><span class="s2">"student"</span><span class="p">,</span><span class="w">
        </span><span class="p">}</span><span class="w">
    </span><span class="p">],</span><span class="w">
    </span><span class="nl">"response"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"text"</span><span class="p">:</span><span class="w"> </span><span class="s2">"yes, good. And when the battery is full, you need to ____ (disconnect it)"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"speaker"</span><span class="p">:</span><span class="w"> </span><span class="s2">"teacher"</span><span class="p">,</span><span class="w">
    </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>Each <strong>test sample</strong> is given as a JSON object that uses the same format as the training sample but which excludes the reference response. As a result, each test sample has two fields:</p>

<dl>
  <dt>id</dt>
  <dd>a unique identifier for this sample.</dd>
  <dt>utterances</dt>
  <dd>a list of utterances, which corresponds to the preceding dialogue context. Each utterance is a JSON object with a <code class="language-plaintext highlighter-rouge">"text"</code> field containing the utterance and a <code class="language-plaintext highlighter-rouge">"speaker"</code> field containing a unique label for the speaker.</dd>
</dl>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
    </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"test_0000"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"utterances"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"text"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Yes, good! And to charge it up, you need to __ it ___"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"speaker"</span><span class="p">:</span><span class="w"> </span><span class="s2">"teacher"</span><span class="p">,</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"text"</span><span class="p">:</span><span class="w"> </span><span class="s2">"…"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"speaker"</span><span class="p">:</span><span class="w"> </span><span class="s2">"student"</span><span class="p">,</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"text"</span><span class="p">:</span><span class="w"> </span><span class="s2">"connect to the source of electricity"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"speaker"</span><span class="p">:</span><span class="w"> </span><span class="s2">"teacher"</span><span class="p">,</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"text"</span><span class="p">:</span><span class="w"> </span><span class="s2">"i understand"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"speaker"</span><span class="p">:</span><span class="w"> </span><span class="s2">"student"</span><span class="p">,</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"text"</span><span class="p">:</span><span class="w"> </span><span class="s2">"plug it __?"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"speaker"</span><span class="p">:</span><span class="w"> </span><span class="s2">"teacher"</span><span class="p">,</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"text"</span><span class="p">:</span><span class="w"> </span><span class="s2">"in"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"speaker"</span><span class="p">:</span><span class="w"> </span><span class="s2">"student"</span><span class="p">,</span><span class="w">
        </span><span class="p">}</span><span class="w">
    </span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<h2 id="participation">Participation</h2>

<p>The shared task is hosted on <strong>CodaLab</strong> <a class="citation" href="#codalab_competitions">(Pavao et al. 2022)</a>. Anyone participating in the shared task will be asked to register on the CodaLab platform and to comply with the terms and conditions of using the TSCC data.</p>

<h3 id="submission">Submission</h3>

<p>Participants are asked to submit a <strong>JSONL file</strong> with the best generated teacher response for each test sample. Each line of the file corresponds to the generated result for one test sample. This result must be a JSON object with the following fields:</p>
<ul>
  <li>an <code class="language-plaintext highlighter-rouge">"id"</code> field containing the unique identifier that was given in the test sample</li>
  <li>a <code class="language-plaintext highlighter-rouge">"text"</code> field containing the generated teacher utterance</li>
  <li>a <code class="language-plaintext highlighter-rouge">"speaker"</code> field containing a unique label to identify your system</li>
</ul>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"test_0000"</span><span class="p">,</span><span class="w"> </span><span class="nl">"text"</span><span class="p">:</span><span class="w"> </span><span class="s2">"yes!"</span><span class="p">,</span><span class="w"> </span><span class="nl">"speaker"</span><span class="p">:</span><span class="w"> </span><span class="s2">"My System Name"</span><span class="p">}</span><span class="w">
</span><span class="p">{</span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"test_0001"</span><span class="p">,</span><span class="w"> </span><span class="nl">"text"</span><span class="p">:</span><span class="w"> </span><span class="s2">"..."</span><span class="p">,</span><span class="w"> </span><span class="nl">"speaker"</span><span class="p">:</span><span class="w"> </span><span class="s2">"My System Name"</span><span class="p">}</span><span class="w">
</span><span class="p">{</span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"test_0002"</span><span class="p">,</span><span class="w"> </span><span class="nl">"text"</span><span class="p">:</span><span class="w"> </span><span class="s2">"..."</span><span class="p">,</span><span class="w"> </span><span class="nl">"speaker"</span><span class="p">:</span><span class="w"> </span><span class="s2">"My System Name"</span><span class="p">}</span><span class="w">
</span><span class="p">{</span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"test_0003"</span><span class="p">,</span><span class="w"> </span><span class="nl">"text"</span><span class="p">:</span><span class="w"> </span><span class="s2">"..."</span><span class="p">,</span><span class="w"> </span><span class="nl">"speaker"</span><span class="p">:</span><span class="w"> </span><span class="s2">"My System Name"</span><span class="p">}</span><span class="w">
</span><span class="err">...</span><span class="w">
</span></code></pre></div></div>

<h3 id="evaluation">Evaluation</h3>

<p>Submissions are ranked according to <strong>automated dialogue evaluation metrics</strong> that perform a turn-level evaluation of the generated response <a class="citation" href="#yeh_comprehensive_2021">(Yeh et al. 2021)</a>. The <strong>leaderboard rank</strong> is computed as the average rank on BERTScore F1 (a referenced metric for turn-level evaluation) and DialogRPT final average (a reference-free metric for turn-level evaluation).</p>

<ol>
  <li>We use <strong>BERTScore</strong> to evaluate the submitted (i.e., generated) response with respect to the reference (i.e., teacher) response. The metric matches words in submission and reference responses by cosine similarity and produces precision, recall, and F1 scores. See <a href="https://github.com/Tiiiger/bert_score">https://github.com/Tiiiger/bert_score</a> for more information.</li>
  <li>We use <strong>DialogRPT</strong> to evaluate the submitted (i.e., generated) response with respect to the preceding dialogue context. DialogRPT is a set of dialog response ranking models proposed by Microsoft Research NLP Group trained on 100+ millions of human feedback data. See <a href="https://github.com/golsun/DialogRPT">https://github.com/golsun/DialogRPT</a> for more information. The following DialogRPT metrics are used:
    <ul>
      <li><strong>updown</strong>: the average likelihood that the response gets the most upvotes</li>
      <li><strong>human_vs_rand</strong>: the average likelihood that the response is relevant for the given context</li>
      <li><strong>human_vs_machine</strong>: the average likelihood that the response is human-written rather than machine-generated</li>
      <li><strong>final (avg/max)</strong>: the (average/best) weighted ensemble score of the above metrics</li>
    </ul>
  </li>
</ol>

<p>The <strong>top 3 submissions</strong> on the automated evaluation will be targeted for further <strong>human evaluation</strong> on the Prolific crowdsourcing platform. During this manual evaluation, human raters compare a pair of responses (teacher - system or system - system) in terms of three abilities: speak like a teacher, understand a student, help a student <a class="citation" href="#tack_ai_2022">(Tack &amp; Piech 2022)</a>.</p>

<h3 id="important-dates">Important Dates</h3>

<p class="notice--danger"><span style="font-size: smaller;"><b>Note</b>: All deadlines are 11:59pm UTC-12 (anywhere on earth).</span></p>

<table rules="groups">
  <tbody>
    <tr>
      <td><strong>Fri Mar 24, 2023</strong></td>
      <td>Training data release</td>
    </tr>
    <tr>
      <td><strong>Mon May 1, 2023</strong></td>
      <td>Test data release</td>
    </tr>
    <tr>
      <td><strong>Fri May 5, 2023</strong></td>
      <td>Final submissions due</td>
    </tr>
    <tr>
      <td><strong>Mon May 8, 2023</strong></td>
      <td>Results announced</td>
    </tr>
    <tr>
      <td><strong>Fri May 12, 2023</strong></td>
      <td>Results human evaluation announced</td>
    </tr>
    <tr>
      <td><strong>Mon May 22, 2023</strong></td>
      <td>System papers due</td>
    </tr>
    <tr>
      <td><strong>Fri May 26, 2023</strong></td>
      <td>Paper reviews returned</td>
    </tr>
    <tr>
      <td><strong>Tue May 30, 2023</strong></td>
      <td>Camera-ready papers due</td>
    </tr>
    <tr>
      <td><strong>Mon June 12, 2023</strong></td>
      <td>Pre-recorded video due</td>
    </tr>
    <tr>
      <td><strong>July 13, 2023</strong></td>
      <td>Workshop at ACL</td>
    </tr>
  </tbody>
</table>

<!--
## Organizers

 - Anaïs Tack, KU Leuven
- Ekaterina Kochmar, University of Bath
- Zheng Yuan, King’s College London
- Serge Bibauw, Universidad Central del Ecuador
- Chris Piech, Stanford University -->

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="wollny_are_2021">Wollny, Sebastian &amp; Schneider, Jan &amp; Di Mitri, Daniele &amp; Weidlich, Joshua &amp; Rittberger, Marc &amp; Drachsler, Hendrik. 2021. Are We There Yet? - A Systematic Literature Review on Chatbots in Education. <i>Frontiers in Artificial Intelligence</i> 4. 654924. (doi:10.3389/frai.2021.654924)</span></li>
<li><span id="bibauw_dialogue_2022">Bibauw, Serge &amp; Van den Noortgate, Wim &amp; François, Thomas &amp; Desmet, Piet. 2022. Dialogue Systems for Language Learning: A Meta-Analysis. <i>Language Learning &amp; Technology</i> 26(1). accepted.</span></li>
<li><span id="bommasani_opportunities_2021">Bommasani, Rishi &amp; Hudson, Drew A. &amp; Adeli, Ehsan &amp; Altman, Russ &amp; Arora, Simran &amp; von Arx, Sydney &amp; Bernstein, Michael S. et al. 2021. <i>On the Opportunities and Risks of Foundation Models</i>. Center for Research on Foundation Models (CRFM): Stanford University.</span></li>
<li><span id="tack_ai_2022">Tack, Anaïs &amp; Piech, Chris. 2022. The AI Teacher Test: Measuring the Pedagogical Ability of Blender and GPT-3 in Educational Dialogues. In Mitrovic, Antonija &amp; Bosch, Nigel (eds.), <i>Proceedings of the 15th International Conference on Educational Data Mining</i>, vol. 15, 522–529. Durham, United Kingdom: International Educational Data Mining Society. (doi:10.5281/zenodo.6853187)</span></li>
<li><span id="caines_teacherstudent_2020">Caines, Andrew &amp; Yannakoudakis, Helen &amp; Edmondson, Helena &amp; Allen, Helen &amp; Pérez-Paredes, Pascual &amp; Byrne, Bill &amp; Buttery, Paula. 2020. The Teacher-Student Chatroom Corpus. In , <i>Proceedings of the 9th Workshop on NLP for Computer Assisted Language Learning</i>, 10–20. Gothenburg, Sweden: LiU Electronic Press.</span></li>
<li><span id="caines_teacherstudent_2022">Caines, Andrew &amp; Yannakoudakis, Helen &amp; Allen, Helen &amp; Pérez-Paredes, Pascual &amp; Byrne, Bill &amp; Buttery, Paula. 2022. The Teacher-Student Chatroom Corpus Version 2: More Lessons, New Annotation, Automatic Detection of Sequence Shifts. In , <i>Proceedings of the 11th Workshop on NLP for Computer Assisted Language Learning</i>, 23–35. Louvain-la-Neuve, Belgium: LiU Electronic Press.</span></li>
<li><span id="yeh_comprehensive_2021">Yeh, Yi-Ting &amp; Eskenazi, Maxine &amp; Mehri, Shikib. 2021. A Comprehensive Assessment of Dialog Evaluation Metrics. In , <i>The First Workshop on Evaluations and Assessments of Neural Conversation Systems</i>, 15–33. Online: Association for Computational Linguistics. (doi:10.18653/v1/2021.eancs-1.3)</span></li>
<li><span id="li_acuteeval_2019">Li, Margaret &amp; Weston, Jason &amp; Roller, Stephen. 2019. ACUTE-EVAL: Improved Dialogue Evaluation with Optimized Questions and Multi-turn Comparisons. arXiv. (doi:10.48550/arXiv.1909.03087)</span></li>
<li><span id="chang_convokit_2020">Chang, Jonathan P. &amp; Chiam, Caleb &amp; Fu, Liye &amp; Wang, Andrew &amp; Zhang, Justine &amp; Danescu-Niculescu-Mizil, Cristian. 2020. ConvoKit: A Toolkit for the Analysis of Conversations. In , <i>Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue</i>, 57–60. 1st virtual meeting: Association for Computational Linguistics.</span></li>
<li><span id="codalab_competitions">Pavao, Adrien &amp; Guyon, Isabelle &amp; Letournel, Anne-Catherine &amp; Baró, Xavier &amp; Escalante, Hugo &amp; Escalera, Sergio &amp; Thomas, Tyler &amp; Xu, Zhen. 2022. CodaLab Competitions: An Open Source Platform to Organize Scientific Challenges. <i>Technical report</i>.</span></li></ol>

        
      </section>

      <footer class="page__meta">
        
        


        
      </footer>

      

      
    </div>

    
  </article>

  
  
</div>

    </div>

    

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
          <li><a href="https://twitter.com/aclsigedu" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/sigedu-org/website" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
    

    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2023 SIGEDU. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script defer src="https://use.fontawesome.com/releases/v5.8.2/js/all.js" integrity="sha384-DJ25uNYET2XCl5ZF++U8eNxPWqcKohUUBUpKGlNLMchM7q4Wjg2CUpjHLaL8yYPH" crossorigin="anonymous"></script>










  </body>
</html>
